---
title: "TensorFlow: Advanced Techniques"
layout: single
---

> Coursera의 "TensorFlow: Advanced Techniques" 과정의 학습강좌 및 텐서플로우 노트북 입니다.

## Class 1. Custom Models, Layers, and Loss Functions
### (1) Functional APIs
* [Lecture Notes][c1-w1]
* Introduction to Functional APIs ([Video][c1-w1-v1])
  * [Fuctional API Practice][c1-w1-n1]
* Using the Functional APIs
  * Declaring the Stacking layers ([Video][c1-w1-v2])
  * Branching models ([Video][c1-w1-v3], [Inception Model][c1-w1-r3])
* Creating Multi-Output Architecture
  * Creating a Multi-Output Model ([Video][c1-w1-v4], [Energy Efficiency Dataset][c1-w1-r4])
  * Multi-Output code ([Video][c1-w1-v5], [Notebook][c1-w1-n5])
* Siamese network
  * Siamese network: A multiple-input model ([Video][c1-w1-v6], [R1][c1-w1-r61], [R2][c1-w1-r62])
  * Coding a Multi-Input Siamese network ([Video][c1-w1-v7], [Vector Distance][c1-w1-r7])
  * Siamese Network code ([Video][c1-w1-v8], [Notebook][c1-w1-n8])
* Assignment: [Functional API][c1-w1-hw]

### (2) Custom Loss Functions
* [Lecture Notes][c1-w2]
* Custom loss functions
  * Creating a custom loss tunction ([Video][c1-w2-v1], [Huber Loss][c1-w2-r1])
  * Coding the Huber loss function ([Video][c1-w2-v2])
  * Huber loss code ([Video][c1-w2-v3], [Notebook][c1-w2-n3])
* Custom loss hyperparameters and classes
  * Adding hyperparameters to custom loss functions ([Video][c1-w2-v4])
  * Turnng oss functions into classes ([Video][c1-w2-v5])
  * Huber Object Loss code ([Video][c1-w2-v6], [Notebook][c1-w2-n6])
* Contrastive Loss
  * Contrastive Loss ([Video][c1-w2-v7])
  * [Dimentionality Reduction by learning an invariant mapping][c1-w2-r7]
  * Coding Contrastive Loss ([Video][c1-w2-v8], [Notebook][c1-w1-n8])
* Assignment: [Custom Loss][c1-w2-hw]

### (3) Custom Layers
* [Lecture Notes][c1-w3]
* Custom lambda layers
  * Intro custom layers
  * Introduction to Lambda layers ([Video][c1-w3-v1])
  * Custom Functions from Lambda Layers ([Video][c1-w3-v2])
  * Exploring custom ReLU with Lambda Layers ([Video][c1-w3-v3], [Notebook][c1-w3-n3])
* Implementing Custom Layers
  * Architecture of a Custom Layer ([Video][c1-w3-v4])
  * Coding your own custom Dense Layer ([Video][c1-w3-v5])
  * Training a neural network with your Custom Layer ([Video][c1-w3-v6])
  * Custom Layer code walkthrough ([Video][c1-w3-v7], [Notebook][c1-w3-n7])
* Activating Custom Layers
  * Activating your Custom Layer ([Video][c1-w3-v8])
  * Custom Layer with activation code walkthrough ([Video][c1-w3-v9], [Notebook][c1-w3-n9])
* Assignment: [Custom Layers][c1-w3-hw]

### (4) Custom Models
* [Lecture Notes][c1-w3]
* Complex Architectures with the Functional API
  * Intro to custom models
  * Complex architectures with the Functional API ([Video][c1-w4-v1], [Wide & Deel Learning][c1-w4-r1])
  * Coding a Wide and Deep model ([Video][c1-w4-v2], [Notebook][c1-w4-n2])
* Using the Model class to simplyfy complex architectures
  * Using the Model class to simplify architectures ([Video][c1-w4-v3])
  * Understanding Residual Networks ([Video][c1-w4-v4])
  * [Residual Networks Lecture (Andew Ng)][c1-w4-v42]
* Implementing ResNet
  * Coding a Residual network with the Model class ([Video][c1-w4-v5])
  * ResNet code ([Video][c1-w4-v6], [Notebook][c1-w4-n6])
* Assignment: [Custom Models][c1-w4-hw]

### (5) Callbacks
* [Lecture Notes][c1-w3]
* Built-in Callbacks ([Video][c1-w5-v1], [Notebook][c1-w5-n1])
  * [TensorBoard Visualization toolkit][c1-w5-t1]
* Custom Callbacks ([Video][c1-w5-v2])
  * Custom Callbacks code ([Video][c1-w5-v2], [Notebook][c1-w5-n3])

[c1-w1]: https://drive.google.com/file/d/1YNGXi_fVtB7wNUTIKK957ull5Uh4_llI/view
[c1-w2]: https://drive.google.com/file/d/1YO4FgTHerrWhnHizqhHujCYAxuws_EBJ/view
[c1-w3]: https://drive.google.com/file/d/1YOO9CpprFAbgWAvHVRDpuY0D_cpX43Uv/view
[c1-w4]: https://drive.google.com/file/d/1YMIVA023JO6AExA7v29JOGEHNy-WQ_Op/view
[c1-w5]: https://drive.google.com/file/d/1YN7jB6OHE2_9toKdjQV114vxQswUW4r9/view
[c1-w1-v1]: https://drive.google.com/file/d/1W2odw1Cu9_JDGX1Z2v4T79QlwYf7wX3p/view?usp=sharing
[c1-w1-n1]: https://colab.research.google.com/drive/1XetZl59T4cL3ouYkbBUDv0PhxnG8uDII
[c1-w1-v2]: https://drive.google.com/file/d/1W9g9zV49CFQcGcxzicwNCC5DGjXZJZEL/view?usp=sharing
[c1-w1-v3]: https://drive.google.com/file/d/1WH3cG1cq-dVAPLP4gltR3PGozI5_8K86/view?usp=sharing
[c1-w1-r3]: https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202
[c1-w1-v4]: https://drive.google.com/file/d/1WKNABXV8EBfxSBRsBH6BLQLWNe4dVY5z/view?usp=sharing
[c1-w1-r4]: https://archive.ics.uci.edu/ml/datasets/Energy+efficiency
[c1-w1-v5]: https://drive.google.com/file/d/1WNByqEChN6FTXk3gLyteOldSbjhBsqz1/view?usp=sharing
[c1-w1-n5]: https://colab.research.google.com/drive/1XirayJkdRFf_345nNh-AlSMm-taES1UT
[c1-w1-v6]: https://drive.google.com/file/d/1WRqwQqfIisxEFDMnq6clc_cNpgNDIRM5/view?usp=sharing
[c1-w1-r61]: https://drive.google.com/file/d/1XyhF3XYGtCPt_cSF7YsYd6iwtzAKVOye/view?usp=sharing
[c1-w1-r62]: https://drive.google.com/file/d/1XnnzbecmtndFFgkPkV8bxgR9YgMzPzgt/view?usp=sharing
[c1-w1-v7]: https://drive.google.com/file/d/1WUU87o9SvOYAWmoR777p_22DlbkkDcj5/view?usp=sharing
[c1-w1-r7]: http://mathonline.wikidot.com/the-distance-between-two-vectors
[c1-w1-v8]: https://drive.google.com/file/d/1WZQa83VRQUfHp5TkD3feP5wPHnE9V-FI/view?usp=sharing
[c1-w1-n8]: https://colab.research.google.com/drive/1Y1xwPR88cgAW_NTowRGk2Nusn7O8bVy7
[c1-w1-hw]: https://colab.research.google.com/drive/1boc73_32egSNYT44ZReeoYKudzHywOzO
[c1-w2-v1]: https://drive.google.com/file/d/1WaQF2JTvWakTEExkERmjpf79SyWqoSfC/view?usp=sharing
[c1-w2-r1]: https://en.wikipedia.org/wiki/Huber_loss
[c1-w2-v2]: https://drive.google.com/file/d/1WjEzjbcas8HUF-GvNymjofZs30MLuCGR/view?usp=sharing
[c1-w2-v3]: https://drive.google.com/file/d/1WklBTOQNXpJie7_x9e4dplRU0hXHSTMQ/view?usp=sharing
[c1-w2-n3]: https://colab.research.google.com/drive/1YABSS1lo_bSHyRw27NFq7kDtwwC-0PuS
[c1-w2-v4]: https://drive.google.com/file/d/1X9NEw7jYeh4Rr6sCtwDXvRcUim85BRcy/view?usp=sharing
[c1-w2-v5]: https://drive.google.com/file/d/1XBbu8RK7Nhc-npNcanbB2imqcAdDIBQY/view?usp=sharing
[c1-w2-v6]: https://drive.google.com/file/d/1XDZ7_qcDo8B98V6kNrVeUk8upy3NPrdl/view?usp=sharing
[c1-w2-n6]: https://colab.research.google.com/drive/1YAHwK2gO5heMGuWoaWBeD4NLeTOzAdtm
[c1-w2-v7]: https://drive.google.com/file/d/1XJ_xMjd_tg-90RNBaBLFpL2rJ6xmzmNu/view?usp=sharing
[c1-w2-r7]: https://drive.google.com/file/d/1YAfvSKqiQEDP6T4qf1Q9H5efWIH3dWxb/view?usp=sharing
[c1-w2-v8]: https://drive.google.com/file/d/1XLKNoTU5JDvPMNjGs9T9-lC_wx_8sWky/view?usp=sharing
[c1-w2-hw]: https://colab.research.google.com/drive/1bslqOGO-MswFNOnF9Et_WyMgKaW1el-I
[c1-w3-v1]: https://drive.google.com/file/d/1XRy8aDfY796CZ_D6G1CfPBRihKq891wg/view?usp=sharing
[c1-w3-v2]: https://drive.google.com/file/d/1YDJ2Ub0N56zvnHRrDtgZljgWLyBwYr4t/view?usp=sharing 
[c1-w3-v3]: https://drive.google.com/file/d/1YDkrnmvLUK6vKNdmLQKCgkfJTTZzTmMx/view?usp=sharing
[c1-w3-n3]: https://colab.research.google.com/drive/1YNxMqCR0PEilA5O7RSZ8Hwd5Sgcoyv0o
[c1-w3-v4]: https://drive.google.com/file/d/1YW-QzNWfadV9Di_cdZDYOIaV-XLAyf_R/view?usp=sharing
[c1-w3-v5]: https://drive.google.com/file/d/1YZNXyWJZI1RrsL7uA1bDRNUajWut_ceA/view?usp=sharing
[c1-w3-v6]: https://drive.google.com/file/d/1YXPls3tQ2Xk7oVmwmbgGkjUsn4_qP7ix/view?usp=sharing
[c1-w3-v7]: https://drive.google.com/file/d/1YgCjnw-5N5B9OZ_8XFDZ_uhbOHI9IwLS/view?usp=sharing
[c1-w3-n7]: https://colab.research.google.com/drive/1YPMTynQSsoCdInGjJHu4KlqtAcPQJ79g
[c1-w3-v8]: https://drive.google.com/file/d/1Ymch_xqg_NYaYRP8V_oBQPYXLR0Gqash/view?usp=sharing
[c1-w3-v9]: https://drive.google.com/file/d/1Yj92O3sV77JT7amETjoFZiLUQMpBhRYS/view?usp=sharing
[c1-w3-n9]: https://colab.research.google.com/drive/1YTEdaw_MlAwfngfwjFuiRwjh2gH5GPHd
[c1-w3-hw]: https://colab.research.google.com/drive/1bvCrI4OXB7hQz4QLyAIuGxJmPKOwskhR
[c1-w4-v1]: https://drive.google.com/file/d/1YqVqFm50sxkENH__P8hNRhngFPLQ0aM2/view?usp=sharing
[c1-w4-r1]: https://blog.research.google/2016/06/wide-deep-learning-better-together-with.html
[c1-w4-v2]: https://drive.google.com/file/d/1ZCsKzmSH6ky2Y44qCfVy4cwcx5hSs0cT/view?usp=sharing
[c1-w4-n2]: https://colab.research.google.com/drive/1Z6f93etiVw2MNyx9XxNDxwzuPdvpjYNp
[c1-w4-v3]: https://drive.google.com/file/d/1ZHM42gSATcwf007QPnhbWFRxZG8sNY70/view?usp=sharing
[c1-w4-v4]: https://drive.google.com/file/d/1ZLxOhO_wnVspVK2EkEbtuywmNpYhmbM-/view?usp=sharing
[c1-w4-v42]: https://drive.google.com/file/d/1ZNnVnInLiuMuNx2ZIW7RGX6k8AqyiLIg/view?usp=sharing
[c1-w4-v5]: https://drive.google.com/file/d/1ZOfyfZ2c_oNnHV_4hegYuWQ_r3VDQH0F/view?usp=sharing
[c1-w4-v6]: https://drive.google.com/file/d/1ZQJcQdEFjEmOESmlEgYU7fBIl42R6_NZ/view?usp=sharing
[c1-w4-n6]: https://colab.research.google.com/drive/1ZSBPa5s6o8RD7BmyCb8ZJNHjZokCSCiP
[c1-w4-hw]: https://colab.research.google.com/drive/1bxCXZsFM7gvtY6YU4gipiWkcth8RnMU2
[c1-w5-v1]: https://drive.google.com/file/d/1ZXtKRSMtbe4I6kwnhreTLn-bzDK9G1pa/view?usp=sharing
[c1-w5-t1]: https://www.tensorflow.org/tensorboard
[c1-w5-n1]: https://colab.research.google.com/drive/1Zd6i_W_8uaOiLBVx5_TGJNf2L8WKvA8q
[c1-w5-v2]: https://drive.google.com/file/d/1Zit6iTSFwHvCzRnKQa79XpTlcXDOoWRs/view?usp=sharing
[c1-w5-v3]: https://drive.google.com/file/d/1ZkHp7mvopq9s_i57dSNfvLueMTWxPhQS/view?usp=sharing
[c1-w5-n3]: https://colab.research.google.com/drive/1ZmZwvZJNAzDhlG1GevT2vCbcTYdCIWyF

## Class 2. Custom and Distributed Training
### (1) Differentiation and Gradients
* [Lecture Notes][c2-w1]
* Tensor Basics
  * What is a tensor? ([Video][c2-w1-v1])
  * Creating Tensors in code ([Video][c2-w1-v2])
  * Math operations with Tensors ([Video][c2-w1-v3])
  * Basic Tensors code ([Video][c2-w1-v4], [Notebook][c2-w1-n4])
* Working with Tensors in Eager Mode
  * Broadcasting, operator overloading and Numpy compatibility ([Video][c2-w1-v5])
  * Evaluating variables and changing data types ([Video][c2-w1-v6])
* Gradient Tape ([Video][c2-w1-v7])
  * [CNN for Visual Recognition][c2-w1-r7]
  * Gradient Descent using Gradient Tape ([Video][c2-w1-v8])
  * Calculate gradients on higher order functions ([Video][c2-w1-v9])
  * Persistent=true and higher order gradients ([Video][c2-w1-v10])
  * Gradient Tape basics code walkthrough ([Video][c2-w1-v11], [Notebook][c2-w1-n11])
* Assignment: [Basic Tensor Operations][c2-w1-hw]

### (2) Custom Training
* [Lecture Notes][c2-w2]
* Custom Training Loops
  * Custom Training Loop steps ([Video][c2-w2-v1])
  * Loss and gradient descent ([Video][c2-w2-v2])
  * Define Training Loop and Validate Model ([Video][c2-w2-v3])
  * Training Basics code ([Video][c2-w2-v4], [Notebook][c2-w2-n4])
* Custom Traing with TensorFlow Datasets
  * Training steps and data pipeline ([Video][c2-w2-v5])
  * Define the training loop ([Video][c2-w2-v6])
  * Gradients, metrics, and validation ([Video][c2-w2-v7])
  * [tf.keras.metrics][c2-w2-r7]
  * Fashion MNIST Custom Training Loop code ([Video][c2-w2-v8], [Notebook][c2-w2-n8])
* Assignment: [Breast Cancer Prediction][c2-w2-hw]

### (3) Graph Mode
* [Lecture Notes][c2-w3]
* AutoGraph
  * Benefits of Graph mode ([Video][c2-w3-v1])
  * Generating Graph code ([Video][c2-w3-v2], [Fizz Buz][c2-w3-r2]
  * AutoGraph Basics code ([Video][c2-w3-v3], [Notebook][c2-w3-n3])
* Creating Graphs for Complex Code
  * Control dependencies and flows ([Video][c2-w3-v4])
  * Loops and tracing variables ([Video][c2-w3-v5])
  * AutoGraph code ([Video][c2-w3-v6], [Notebook][c2-w3-n6])
* Assignment: [AutoGraph][c2-w3-hw]

### (4) Distributed Training
* [Lecture Notes][c2-w4]
* Overview of Distribution Strategies
  * Intro to distribution strategies ([Video][c2-w4-v1])
  * Types of distribution strategies ([Video][c2-w4-v2])
* Mirrored Strategy
  * Converting code to the Mirrored Strategy ([Video][c2-w4-v3])
  * Mirrored Strategy code ([Video][c2-w4-v4], [Notebook][c2-w4-n4])
* Multiple GPU Mirrored Strategy
  * Custom Training for Multiple GPU Mirrored Strategy ([Video][c2-w4-v5])
  * Multi GPU Mirrored Strategy code ([Video][c2-w4-v6], [Notebook][c2-w4-n6])
* TPU Strategy ([Video][c2-w4-v7])
  * TPU Strategy code ([Video][c2-w4-v8], [Notebook][c2-w4-n8])
* Other Distributed Strategies ([Video][c2-w4-v9], [Ref][c2-w4-r9])
  * [One Device Strategy][c2-w4-n9]
* Assignment: [Distributed Strategy][c2-w4-hw]

[c2-w1]: https://drive.google.com/file/d/1YTjRjk-TfPsvK8_guPRHYoeKy5HOWK54/view
[c2-w2]: https://drive.google.com/file/d/1YUMMmzsDE4s6ENU9eFuTub6QMpThSvd5/view
[c2-w3]: https://drive.google.com/file/d/1YPXGiP7ECc7Q-3gflISrgooHou1EC2Eu/view
[c2-w4]: https://drive.google.com/file/d/1YSkmpLZqOkFxNqfi04_J8h8oTgRNtr-O/view
[c2-w1-v1]: https://drive.google.com/file/d/1W__6HcU7XEbnEoH3rinF-jXKgTLZ2ndL/view?usp=sharing
[c2-w1-v2]: https://drive.google.com/file/d/1WJuLPruMypp00_TXDjlTw7DiPtj0H2CG/view?usp=sharing
[c2-w1-v3]: https://drive.google.com/file/d/1WHzACtpevwiEyP7xbxVbfzsTo4TJ8CDF/view?usp=sharing
[c2-w1-v4]: https://drive.google.com/file/d/1XANRlF3RNEvQcX93M5S_O4T_1cxqdG-B/view?usp=sharing
[c2-w1-n4]: https://colab.research.google.com/drive/1Wnn82lCK1VE468K5fMluRk_vHklids0Y
[c2-w1-v5]: https://drive.google.com/file/d/1XS1kGbLOwzVm_r0GeY4d3YCKVnYQ6JSL/view?usp=sharing
[c2-w1-v6]: https://drive.google.com/file/d/1XfIwQtDBJr5fuEFwnjMaX0tsJlET75m7/view?usp=sharing
[c2-w1-v7]: https://drive.google.com/file/d/1_ANEGVna7rMlOJt6UzXjsUkI2sFFMiw1/view?usp=sharing
[c2-w1-r7]: https://cs231n.github.io/neural-networks-3/
[c2-w1-v8]: https://drive.google.com/file/d/1_CDPqc_LgkWshF8TGNrWF9hWs5VjhzNc/view?usp=sharing
[c2-w1-v9]: https://drive.google.com/file/d/1Zw4sk2B9_iX0XJXmXljDku-sVqfZCE-l/view?usp=sharing
[c2-w1-v10]: https://drive.google.com/file/d/1_38QOR0zrMw410oiREGMuaOd0toRtxQR/view?usp=sharing
[c2-w1-v11]: https://drive.google.com/file/d/1_6ZR616VonQL1Mtrc7qs0yP5Dher463c/view?usp=sharing
[c2-w1-n11]: https://colab.research.google.com/drive/1ZtazBmCqqBaMHYZvHF7pfgi-L-Y0K7k2
[c2-w1-hw]: https://colab.research.google.com/drive/1byNykyuLa_p2zM-H1mBgeqe2-CSrJBfz
[c2-w2-v1]: https://drive.google.com/file/d/1_HkkxGhSA4Lt1m_suUkdGi3FkB3CGuuN/view?usp=sharing
[c2-w2-v2]: https://drive.google.com/file/d/1_GFHsuT0Flfe_cMgYj1hdNKEU8YSUk54/view?usp=sharing
[c2-w2-v3]: https://drive.google.com/file/d/1_Kp-JfEnTvlCKpIOZr-lJNCb0zEaTOX6/view?usp=sharing
[c2-w2-v4]: https://drive.google.com/file/d/1_J6gfS4DNGosDmSS2VEzgYy8DTWJ8CVv/view?usp=sharing
[c2-w2-n4]: https://colab.research.google.com/drive/1_Et5PDEh0O61fSgFzbPjmt5LWAFwvcQD
[c2-w2-v5]: https://drive.google.com/file/d/1_esASuS8uQYOFYCuNuZtWIwrWwZS8-Il/view?usp=sharing
[c2-w2-v6]: https://drive.google.com/file/d/1_THtCv31W3bn0fvWJ06Qqalv3BE4XejB/view?usp=sharing
[c2-w2-v7]: https://drive.google.com/file/d/1_SFhZj4BWRFKmp5LLgZdAzVjOCRim6dZ/view?usp=sharing
[c2-w2-r7]: https://www.tensorflow.org/api_docs/python/tf/keras/metrics
[c2-w2-v8]: https://drive.google.com/file/d/1_QIf_xSb-rdH5vN7ddQBH_H-51dLlYaj/view?usp=sharing
[c2-w2-n8]: https://colab.research.google.com/drive/1_fdiuMSe-4O5BfDN0ARkcTCT0YafEwKo
[c2-w2-hw]: https://colab.research.google.com/drive/1bzE0Bco5MmHbjXHa48FFs-NQBd4tUSi7
[c2-w3-v1]: https://drive.google.com/file/d/1_pBPLguEhlB3TLrMh3uxQojSamgLFH1X/view?usp=sharing
[c2-w3-v2]: https://drive.google.com/file/d/1_udoy77hjREz_DeXbN6RE2eWudTkMMQO/view?usp=sharing
[c2-w3-r2]: http://wiki.c2.com/?FizzBuzzTest
[c2-w3-v3]: https://drive.google.com/file/d/1_xWTgrkNTjp6MR1C0Kk2BAMiuNY4AR_R/view?usp=sharing
[c2-w3-n3]: https://colab.research.google.com/drive/1_hJF0_n_C0DxPRm_hIBgYRTwqFSb39l-
[c2-w3-v4]: https://drive.google.com/file/d/1a1jRMG9HC8x8L1MckPRxUfrYN7pu-bL8/view?usp=sharing
[c2-w3-v5]: https://drive.google.com/file/d/1a4DlcF2vxwETLRCgoL5AFeGAwbKs92nq/view?usp=sharing
[c2-w3-v6]: https://drive.google.com/file/d/1a11lXXtJE9alW8oeZYMFWeb1xOAem1Rl/view?usp=sharing
[c2-w3-n6]: https://colab.research.google.com/drive/1_zrMXcAsatGnpxis2KY0X4z-bDIfniV1
[c2-w3-hw]: https://colab.research.google.com/drive/1bzOX-Yv4KkmvjlTIVJ0pEnwcOSPnEM5M
[c2-w4-v1]: https://drive.google.com/file/d/1kaHlOj-qKS6zLbmrl2LfoHdvFAYKCcEG/view?usp=sharing
[c2-w4-v2]: https://drive.google.com/file/d/1kMccZLXEi8Fhe9J1cr2r-png95L9QFnL/view?usp=sharing
[c2-w4-v3]: https://drive.google.com/file/d/1kLN_XyWZ3zJS5-2GrZugWXw6huQcRkgR/view?usp=sharing
[c2-w4-v4]: https://drive.google.com/file/d/1jvWRx2gCCm5q4iHxLbXLi3Hqc-BP2I3b/view?usp=sharing
[c2-w4-n4]: https://colab.research.google.com/drive/1kinOj9VLm9AfD7wnrSDtLvNelwce4E9v
[c2-w4-v5]: https://drive.google.com/file/d/1l84EN9gH9FjSyInRagh43yJJeVRqGiZI/view?usp=sharing
[c2-w4-v6]: https://drive.google.com/file/d/1l4LlkDNvUEZVR8UqjKk0ijhucvb6DwoX/view?usp=sharing
[c2-w4-n6]: https://colab.research.google.com/drive/1kmj1CrdxsaPnQtNHjwiyDYVlEklHOzZ9
[c2-w4-v7]: https://drive.google.com/file/d/1l-fUkF0_iMHSSKV9tb4yfjnHCBR9pj4z/view?usp=sharing
[c2-w4-v8]: https://drive.google.com/file/d/1l8EcAZ5n0fW-zgma7i_Ymw6vaux4nDcN/view?usp=sharing
[c2-w4-n8]: https://colab.research.google.com/drive/1kk1_s4wlL4RmWApV7e6UEGx5yjdQRwff
[c2-w4-v9]: https://drive.google.com/file/d/1lCwgX9MjRxdNN769Xgom-fhhHSFZR7jX/view?usp=sharing
[c2-w4-r9]: https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras
[c2-w4-n9]: https://colab.research.google.com/drive/1ks2FXDSqSa5YHMQx3Ihx_ssmo81hjUgD
[c2-w4-hw]: https://colab.research.google.com/drive/1c0P2lXcEE57HxmKzIoIIBx9ggnrqZlkv

## Class 3. Advanced Computer Vision
### (1) Introduction to Computer Vision
* [Lecture Notes][c3-w1]
* Concepts in Computer Vision
  * Classification and Object Detection Intro ([Video][c3-w1-v1])
  * Segmentation Intro ([Video][c3-w1-v2])
  * References: [Semantic Segmentation][c3-w1-r21], [U-Net][c3-w1-r22], [DeepLab][c3-w1-r23], [Mask R-CNN][c3-w1-r24]
* Trasfer Learning
  * Why Transfer Learning? ([Video][c3-w1-v3])
  * What is Transfer Learning? ([Video][c3-w1-v4])
  * Options in Transfer Learning ([Video][c3-w1-v5], [Notebook][c3-w1-n5])
* Advanced Trasfer Learning
  * Transfer Learning with ResNet50 ([Video][c3-w1-v6])
  * ResNet50 in code ([Video][c3-w1-v7], [Notebook][c3-w1-n7])
* Object Localization and Detection
  * Network architecture for Object Localization ([Video][c3-w1-v8])
  * Evaluating Object Localization ([Video][c3-w1-v9])
  * [Image Classification and Object Localization][c3-w1-n9]
* Assignment: [Bird Boxes][c3-w1-hw]

### (2) Object Detection 
* [Lecture Notes][c3-w2]
* Object Detection
  * Object Detection and Sliding Windows ([Video][c3-w2-v1])
  * References: [Amazon][c3-w2-r11], [PowerAI][c3-w2-r12], [DIGITS][c3-w2-r13]
  * R-CNN ([Video][c3-w2-v2])
  * Fast R-CNN ([Video][c3-w2-v3])
  * Faster R-CNN ([Video][c3-w2-v4])
  * References: [R-CNN][c3-w2-r41], [Fast R-CNN][c3-w2-r42]
* Object Detection in TensorFlow
  * Getting the Model from TensorFlow Hub ([Video][c3-w2-v5], [TF Hub][c3-w2-r5])
  * Running the Model on an Image ([Video][c3-w2-v6])
  * [Implement Simple Object Detection][c3-w2-n61]
  * [Predicting Bounding Boxes for Object Detection][c3-w2-n62]
* Object Detection APIs
  * Installation and overview of APIs ([Video][c3-w2-v7])
  * Visualization with APIs ([Video][c3-w2-v8])
  * References: [R1][c3-w2-r81], [R2][c3-w2-r82], [R3][c3-w2-r83]
  * Object Detection API : [Official Tutorial][c3-w2-r84], [Example][c3-w2-e84]
* Retraining with the Object Detection API
  * Loading a RetinaNet Model ([Video][c3-w2-v9])
  * References: [RetinaNet][c3-w2-r91], [Model Garden][c3-w2-r92]
  * Loading Weights ([Video][c3-w2-v10])
  * Data Prep and Training Overview ([Video][c3-w2-v11])
  * Custom Training Loop Code ([Video][c3-w2-v12])
  * [Eager Few Shot Object Detection][c3-w2-n12]
* Assignment: [Zombie Detector][c3-w2-hw]

### (3) Image Segmentation 
* [Lecture Notes][c3-w3]
* Image Segmentation Overview ([Video][c3-w3-v1])
  * Popular Image Segmentation Architectures ([Video][c3-w3-v2], [FCN][c3-w3-r2])
  * FCN Architecture Details ([Video][c3-w3-v3])
  * Upsampling Methods ([Video][c3-w3-v4])
  * Encoder in Code ([Video][c3-w3-v5], [CamVid][c3-w3-r5])
  * Decoder in Code ([Video][c3-w3-v6])
  * Evaluation with IoU and Dice Score ([Video][c3-w3-v7])
  * [Implement a Fully CNN (Lab-1)][c3-w3-n7]
* U-Net
  * U-Net Overview ([Video][c3-w3-v8], [U-Net][c3-w3-r8])
  * U-Net Code: Encoder ([Video][c3-w3-v9])
  * U-Net Code: Decoder ([Video][c3-w3-v10])
  * [Implement a U-Net (Lab-2)][c3-w3-n9]
* Instance Segmentation ([Video][c3-w3-v11])
  * [Instance Segmentation Demo (Lab-3)][c3-w3-n11]
* Assignment: [Image Segmentation of Handwritten Digits][c3-w3-hw]

### (4) Visualization and Interpretability
* [Lecture Notes][c3-w4]
* Intro to Visualization and Interpretation
  * Why Interpretation Matters? ([Video][c3-w4-v1])
  * Class Activation Maps ([Video][c3-w4-v2])
  * Fashion MNIST Class Activation Map code ([Video][c3-w4-v3], [N1][c3-w4-n31], [N2][c3-w4-n32])
* Saliency ([Video][c3-w4-v4])
  * [Saliency Maps][c3-w4-n4])
* Gradients and Class Activation Maps
  * GradCAM ([Video][c3-w4-v5], [GradCAM][c3-w4-r5],  [Notebook][c3-w4-n5])
* Improving a model with a interpretation
  * ZFNet ([Video][c3-w4-v6], [ZFNet][c3-w4-r6])
* Assignment: [Cats vs Dogs Saliency Maps][c3-w4-hw]

[c3-w1]: https://drive.google.com/file/d/1YUOT19MX7VJb-iIMtcpyTCc83Sr2cylf/view
[c3-w2]: https://drive.google.com/file/d/1YUzp4BlV5he3jsaCdSPx269oiFRVSude/view
[c3-w3]: https://drive.google.com/file/d/1YZ4VVkw2oUo85G4E9-CxQS1pC_5gJVnp/view
[c3-w4]: https://drive.google.com/file/d/1YUnz-rx_kYJIPUvtxTpGhpZK1INVsmvd/view
[c3-w1-v1]: https://drive.google.com/file/d/1aNKmaTCUPvmbd4fVx4Lgaqy-z_6WP-9J/view?usp=sharing
[c3-w1-v2]: https://drive.google.com/file/d/1aL0pDezVewUrgUR0QPjkrnxt8AGkHBSx/view?usp=sharing
[c3-w1-r21]: https://openaccess.thecvf.com/content_cvpr_2015/html/Long_Fully_Convolutional_Networks_2015_CVPR_paper.html
[c3-w1-r22]: https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/
[c3-w1-r23]: http://liangchiehchen.com/projects/DeepLab.html
[c3-w1-r24]: https://arxiv.org/abs/1703.06870
[c3-w1-v3]: https://drive.google.com/file/d/1aY9oFlG6dEvOMgvZwQgnl9R_zTEN6DeR/view?usp=sharing
[c3-w1-v4]: https://drive.google.com/file/d/1aV2gLD46Yy138kYpyV0ey6GAdV1urkhp/view?usp=sharing
[c3-w1-v5]: https://drive.google.com/file/d/1aXZE8m0pmhdtM5HprjUMBXvc_sLPjQ6H/view?usp=sharing
[c3-w1-n5]: https://colab.research.google.com/drive/1Lsfo48pRFNWBBaS9xGX7B3m5VluvWraq
[c3-w1-v6]: https://drive.google.com/file/d/1h67849xxNpSJmaPx3YMQb-eic5RQYR7n/view?usp=sharing
[c3-w1-v7]: https://drive.google.com/file/d/1gw7PrDCg_GcLb6F6xgtcuwzw8khad7yb/view?usp=sharing
[c3-w1-n7]: https://colab.research.google.com/drive/1QbWZmb3STkVsmdhc0w7YI7eBaZWu1PVv
[c3-w1-v8]: https://drive.google.com/file/d/1ghPebKxhuvHd2lzje1rAFuyprsCo9JF7/view?usp=sharing
[c3-w1-v9]: https://drive.google.com/file/d/1hEvgW93Rs8kJETz20B5tzPh4MjH1axp4/view?usp=sharing
[c3-w1-n9]: https://colab.research.google.com/drive/1wgNV0YzabDfBt6p2TKBf6Im4ciI1-Acy
[c3-w1-hw]: https://colab.research.google.com/drive/1SSaJLdwhblUJC9NLhhl2GOd9k7JOCKbv
[c3-w2-v1]: https://drive.google.com/file/d/1amezLA2-ABU7Wbtu-wlAkHxpEe4U5xlr/view?usp=sharing
[c3-w2-r11]: https://aws.amazon.com/ko/rekognition/?blog-cards.sort-by=item.additionalFields.createdDate&blog-cards.sort-order=desc
[c3-w2-r12]: https://cloud.ibm.com/catalog#services
[c3-w2-r13]: https://developer.nvidia.com/digits
[c3-w2-v2]: https://drive.google.com/file/d/1aklwetfMsHueoq_FAGZm2A9NrQvKSKJj/view?usp=sharing
[c3-w2-v3]: https://drive.google.com/file/d/1aifhvh0eTX4rcKcvks4p70piIUd1hp7j/view?usp=sharing
[c3-w2-v4]: https://drive.google.com/file/d/1aqVEQwYCZ7wOsBOm1S9-48JrpAGISe4m/view?usp=sharing
[c3-w2-r41]: https://arxiv.org/abs/1311.2524
[c3-w2-r42]: https://arxiv.org/abs/1504.08083
[c3-w2-v5]: https://drive.google.com/file/d/1b5QErXuZl7c5RsSB0wJ5zdJPYYMQCUlh/view?usp=sharing
[c3-w2-r5]: https://www.tensorflow.org/hub
[c3-w2-v6]: https://drive.google.com/file/d/1b25uCeFFD1bvc5ZSweO80zcFYnTj3gv6/view?usp=sharing
[c3-w2-n61]: https://colab.research.google.com/drive/1Z8b7pVycEvhSDjRBSI0T_pyJCIZF8QXJ
[c3-w2-n62]: https://colab.research.google.com/drive/1fYxyA9upWqZ2-_kWPbjpYqEFz-r6Wdh3
[c3-w2-v7]: https://drive.google.com/file/d/1bHDemZhescKcRxFzhPluU_1tfo_3m39B/view?usp=sharing
[c3-w2-v8]: https://drive.google.com/file/d/1bFJJ_Drjrh3EyybW4bTfcFSxLOZndfWT/view?usp=sharing
[c3-w2-r81]: https://github.com/tensorflow/models/tree/master/research/object_detection
[c3-w2-r82]: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md
[c3-w2-r83]: https://www.tensorflow.org/guide/checkpoint
[c3-w2-r84]: https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/hub/tutorials/tf2_object_detection.ipynb
[c3-w2-e84]: https://colab.research.google.com/drive/1a8GXoWlXgLs49iLAkVWLeATKKLgPtS6D
[c3-w2-v9]: https://drive.google.com/file/d/1b8O_SP75xsWQh8zIKjKCWyai-HoT_Wig/view?usp=sharing
[c3-w2-r91]: https://arxiv.org/abs/1708.02002
[c3-w2-r92]: https://github.com/tensorflow/models
[c3-w2-v10]: https://drive.google.com/file/d/1b7lB_lxt1GpHqcTSl-bOiBLxvuwSWbEB/view?usp=sharing
[c3-w2-v11]: https://drive.google.com/file/d/1b_8M97-gLNaWnDedoNRuJfEMHFxByo10/view?usp=sharing
[c3-w2-v12]: https://drive.google.com/file/d/1bWjoinpmvt2LdR_JIroIibsaCYqzMW8Y/view?usp=sharing
[c3-w2-n12]: https://colab.research.google.com/drive/1PJIYm2W5d3NnLgqB9tg_8iFTTRUfSKye
[c3-w2-hw]: https://colab.research.google.com/drive/1EuuS2B3l5rqUwBCqzpbK6Clmf9O8G_IO
[c3-w3-v1]: https://drive.google.com/file/d/1iE_T6eXOO1xZZxwHDtkrGF5ktFbnA6eT/view?usp=sharing
[c3-w3-v2]: https://drive.google.com/file/d/1huxSLoA505Pn8p47_TFWOrZD7qEKx2ED/view?usp=sharing
[c3-w3-r2]: https://arxiv.org/abs/1411.4038
[c3-w3-v3]: https://drive.google.com/file/d/1hqdPWwi8OX-DjtdDtPW4vIvTak9DW810/view?usp=sharing
[c3-w3-v4]: https://drive.google.com/file/d/1hlfHwqpMk_COoH0fmu8HQ_zdVAZzbs4D/view?usp=sharing
[c3-w3-v5]: https://drive.google.com/file/d/1hiWkLGbenlnQmat19Zha9HfpdvyOalwV/view?usp=sharing
[c3-w3-r5]: https://github.com/divamgupta
[c3-w3-v6]: https://drive.google.com/file/d/1hWmmklN-5plx-mifBlojql_Hz4Hxoxu9/view?usp=sharing
[c3-w3-v7]: https://drive.google.com/file/d/1iOOm8M7RYmJeB_woF8xa7oowP-Ej0ELJ/view?usp=sharing
[c3-w3-n7]: https://colab.research.google.com/drive/1Ow4bPWrMQcIo5eTTBMlQejpj6GJv7jUS
[c3-w3-v8]: https://drive.google.com/file/d/1j30qqVxy7eWI-ARr2OtvFVVMtUBziwGa/view?usp=sharing
[c3-w3-r8]: https://arxiv.org/abs/1505.04597
[c3-w3-v9]: https://drive.google.com/file/d/1j6u221Hj0cgg2mUITz9FSyN69I3K8tvD/view?usp=sharing
[c3-w3-n9]: https://colab.research.google.com/drive/1_XcNxlcz-gU2753ye7q3y3EzrwVtiKQY
[c3-w3-v10]: https://drive.google.com/file/d/1j5zycjWjtQfpR3-AzjXUyTyrjzAQtwoC/view?usp=sharing
[c3-w3-v11]: https://drive.google.com/file/d/1j5pXMzspmKloUN6-UOBhT6xSTWqDxS2P/view?usp=sharing
[c3-w3-n11]: https://colab.research.google.com/drive/10h0AIZXC_Q9KqCz-92VH3COfFXg0CAQ7
[c3-w3-hw]: https://colab.research.google.com/drive/1Eajy7xxwMFLm00qk6LAIi-nsIVDN-uw1?usp=sharing
[c3-w4-v1]: https://drive.google.com/file/d/1jgUgfHqOmYGpzmfQLZ6P2MoJ8-0VfL8f/view?usp=sharing
[c3-w4-v2]: https://drive.google.com/file/d/1jOU1tSqiSnx-geeaFbx9qTP7SA1ohHnt/view?usp=sharing
[c3-w4-v3]: https://drive.google.com/file/d/1jMUYInaQ7bAfaJEPysOdU_izohvv2JfR/view?usp=sharing
[c3-w4-n31]: https://colab.research.google.com/drive/1xpsybeAO6Dfk4Qzu6_a2Ms3lrQFrg9IQ
[c3-w4-n32]: https://colab.research.google.com/drive/1Aw6PLjk03_kGxMqkpV15tG-GKwVQGKL_
[c3-w4-v4]: https://drive.google.com/file/d/1jM6yloKlv78knp6U7V04UF0xmwngfAwD/view?usp=sharing
[c3-w4-n4]: https://colab.research.google.com/drive/1vSXfGYQ0LIjHqZENH2ewZSoQfSHbHehl
[c3-w4-v5]: https://drive.google.com/file/d/1jFEdQ4MPnZr7DhxLPU7NHZIcKSDRUBeS/view?usp=sharing
[c3-w4-r5]: https://arxiv.org/pdf/1610.02391.pdf
[c3-w4-n5]: https://colab.research.google.com/drive/1aECX1r4B5sm8Kg2kQ2w5Jmkv15JDvjaP
[c3-w4-v6]: https://drive.google.com/file/d/1juJhMY-wUiXMO7so4X83E1VojUfTgxSW/view?usp=sharing
[c3-w4-r6]: https://arxiv.org/abs/1311.2901

[c3-w4-hw]: https://colab.research.google.com/drive/1a0h5GIR7Cgxfp3_jYz9whpE665PPYbvC

## Class 4. Generative Deep Learning
### (1) Style Transfer
* [Lecture Notes][c4-w1]
* Style Transfer Intro
  * Style Transfer Intro ([Video][c4-w1-v1], [A Neural Algorithm of Aartistic Dstyle][c4-w1-r1])
  * Style Transfer Conceptual Overview ([Video][c4-w1-v2], [Perceptual Losses][c4-w1-r2])
  * Pre-Processing Inputs ([Video][c4-w1-v3])
  * Extracting Style and Content Features ([Video][c4-w1-v4], [Visualizing][c4-w1-r4])
  * Total Loss and Content Loss ([Video][c4-w1-v5])
  * Style Loss ([Video][c4-w1-v6], [Einsum][c4-w1-r6])
  * Update the Generated Image ([Video][c4-w1-v7])
  * Gram Matrix ([Video][c4-w1-v8])
  * Einstein Notation ([Video][c4-w1-v9])
  * Einsum in Code ([Video][c4-w1-v10], [Notebook][c4-w1-n10])
  * [Neural Style Transfer][c4-w1-n11]
* Fast Neural Style Transfer ([Video][c4-w1-v12])
  * [Exploring the structure of a real-time, arbitrary neural artistic stylization network][c4-w1-r12]
  * [Fast Neural Style Transfer][c4-w1-n12]
* Assignment: [Style Transfer][c4-w1-hw]

### (2) AutoEncoders
* [Lecture Notes][c4-w2]
* What are AutoEncoders?
  * Introduction ([Video][c4-w2-v1])
  * First AutoEncoder ([Video][c4-w2-v2], [Notebook][c4-w2-n2])
  * MNIST AutoEncoder ([Video][c4-w2-v3], [Notebook][c4-w2-n3])
* Deep AutoEncoders
  * MNIST Deep AutoEncoder ([Video][c4-w2-v4], [Notebook][c4-w2-n4])
  * Convolutional AutoEncoder ([Video][c4-w2-v5], [Notebook][c4-w2-n5])
  * Denoising with an AutoEncoder ([Video][c4-w2-v6], [Notebook][c4-w2-n6])
* Assignment: [AutoEncoder][c4-w2-hw]

### (3) Variational AutoEncoders
* [Lecture Notes][c4-w3]
* Variational AutoEncoders
  * Variational AutoEncoders Overview ([Video][c4-w3-v1])
  * VAE Architecture and Code ([Video][c4-w3-v2])
  * Sampling Layer and Encoder ([Video][c4-w3-v3])
  * Decoder ([Video][c4-w3-v4])
  * Loss Function and Model Definition ([Video][c4-w3-v5])
  * References: [K-L Divergence][c4-w3-r51], [Reconstruction error][c4-w3-r52]
  * Train the VAE Model ([Video][c4-w3-v6], [Notebook][c4-w3-n6], [Convolutional VAE][c4-w3-r6])
* Assignment: [VAE Anime Faces][c3-w3-hw]

### (4) GANs
* [Lecture Notes][c4-w4]
* What are GANs?
  * Introduction ([Video][c4-w4-v1], [Ref][c4-w4-r1])
  * First GAN Architecture ([Video][c4-w4-v2], [Ref][c4-w4-r2])
  * First GAN Training Loop ([Video][c4-w4-v3], [Notebook][c4-w4-n3])
* Deep GANs
  * DCGANs ([Video][c4-w4-v4])
  * References: [Unsupervised Representation Learning][c4-w4-r41], [LeakyReLU][c4-w4-r42]
  * [First DCGAN][c4-w4-n4]
  * Face Generator ([Video][c4-w4-v5])
  * Face Generator Discriminator ([Video][c4-w4-v6])
  * Reference: [Layer Normalization][c4-w4-r6]
  * [CelebA GAN Experiments][c4-w4-n6]
* Assignment: [Generate Hands with GANs][c4-w4-hw]

[c4-w1]: https://drive.google.com/file/d/1YZrjmo-JfS_TmsMUmNiAWNjNP7joO5Bu/view
[c4-w2]: https://drive.google.com/file/d/1YfSyPYyhcSHhmPkXzLHZJdfSeEzsMe8I/view
[c4-w3]: https://drive.google.com/file/d/1YePTYTF-ZUj7TU2DmpeHKmzV9ZlId2_L/view
[c4-w4]: https://drive.google.com/file/d/1YamlWDJeSQzz1bnwqaJO8wmUTFtWJ6LR/view
[c4-w1-v1]: https://drive.google.com/file/d/1YdSt55VPzJj2EPhbPdV3mx-8i-EGgbAX/view?usp=sharing
[c4-w1-r1]: https://arxiv.org/abs/1508.06576
[c4-w1-v2]: https://drive.google.com/file/d/1YX0MIC5_O2vfMTVHVAJBpTJ3J-vEys9Q/view?usp=sharing
[c4-w1-r2]: https://cs.stanford.edu/people/jcjohns/eccv16/
[c4-w1-v3]: https://drive.google.com/file/d/1YAUgN4Xe3zByYbwOZDSiSNgEFp90sWsk/view?usp=sharing
[c4-w1-v4]: https://drive.google.com/file/d/1Y1oa09aBMtnUd9xLz-S-SBzfl1TNJgs5/view?usp=sharing
[c4-w1-r4]: https://drive.google.com/file/d/1a3jtTvko2bCmVnqC0C7A-YwdK3No5alU/view
[c4-w1-v5]: https://drive.google.com/file/d/1YlPEiToTY4S2GichmfOe0UpPFlEko9i8/view?usp=sharing
[c4-w1-v6]: https://drive.google.com/file/d/1ZLrsfcZkMRYXhoSLszXY_G-ODIbgVNbj/view?usp=sharing
[c4-w1-r6]: https://numpy.org/doc/stable/reference/generated/numpy.einsum.html
[c4-w1-v7]: https://drive.google.com/file/d/1ZGn8ZYkUgXl4bjoOpQtj81KzDQPPI1tQ/view?usp=sharing
[c4-w1-v8]: https://drive.google.com/file/d/1ZAkd2LpZLqcZRgkn1ta9DPCRLcjZvl-f/view?usp=sharing
[c4-w1-v9]: https://drive.google.com/file/d/1Z41WjEwAY6hgq7YZWDVfnq8ezLpm2IV_/view?usp=sharing
[c4-w1-v10]: https://drive.google.com/file/d/1YqAW2diG1aMuChXcPqb5aa3wM1WK3e4N/view?usp=sharing
[c4-w1-n10]: https://colab.research.google.com/drive/1NPPyCjWQcYeKbKCWodmeIV0M3siHVC_p
[c4-w1-v11]: https://drive.google.com/file/d/1ZWfZ2YvlRD_qF95Uxr1mG3E6AI3eEpLr/view?usp=sharing
[c4-w1-n11]: https://colab.research.google.com/drive/1GuLYNh6wTDoLgyLZ7gnbxkPLYggbNhoH
[c4-w1-v12]: https://drive.google.com/file/d/1ZYUSdody99xrCmxJTV1Q0h5Eo5z7BPiZ/view?usp=sharing
[c4-w1-r12]: https://arxiv.org/pdf/1705.06830.pdf
[c4-w1-n12]: https://colab.research.google.com/drive/1etV_fhHjIHXTYtQ1mbHn1SuQtPfwonb7
[c4-w1-hw]: https://colab.research.google.com/drive/1m65uVqfnycj4P3bvtNWCpijjYFShe1F_
[c4-w2-v1]: https://drive.google.com/file/d/1Zbft0jvEGkEUnXh1sRObMgtkzBGPZPkr/view?usp=sharing
[c4-w2-v2]: https://drive.google.com/file/d/1ZfUks2QDMkCyZN7XtoGI286cWwXixXda/view?usp=sharing
[c4-w2-n2]: https://colab.research.google.com/drive/1iCh93vtbz5Y3nnr3gxx3tOjKeeKTCHcO
[c4-w2-v3]: https://drive.google.com/file/d/1cgRkYOwac6hcYhBhR8axus1_Hlg4L5io/view?usp=sharing
[c4-w2-n3]: https://colab.research.google.com/drive/1CqTomCUXViDyEKeFShHL73ul_QiqeEns
[c4-w2-v4]: https://drive.google.com/file/d/1cl4vnMMxVyAeDcFXCKrWxqLoLTy_AcM7/view?usp=sharing
[c4-w2-n4]: https://colab.research.google.com/drive/1mUsUPy6WU7L_uCiRnnsP6DlkPeskKPiw
[c4-w2-v5]: https://drive.google.com/file/d/1ciMIWm49a6rTHN4hME5ifuyub1JCSpBt/view?usp=sharing
[c4-w2-n5]: https://colab.research.google.com/drive/1IX_b-e3d_ZUw_GVTbu9zdVCvdbPRhgxU
[c4-w2-v6]: https://drive.google.com/file/d/1chrblJkR4s-AbO6EIyiiyfx7gzWTubLp/view?usp=sharing
[c4-w2-n6]: https://colab.research.google.com/drive/1vTOovtpZZHSjcAjGn14d9cL4BtcmhjKF
[c4-w2-hw]: https://colab.research.google.com/drive/1bzr0xKnxLfSqh2u8ZJcLWpOVYVjK9qnO
[c4-w3-v1]: https://drive.google.com/file/d/1fF-Oeu5qIbNID01DSONkOHdbHLLklR6A/view?usp=sharing
[c4-w3-v2]: https://drive.google.com/file/d/1fRb35IU891RMuPaQfFCQKvigdDShWLwL/view?usp=sharing
[c4-w3-v3]: https://drive.google.com/file/d/1fMVtXB9pKnG7NHPOkohsTOii2GAeT-wz/view?usp=sharing
[c4-w3-v4]: https://drive.google.com/file/d/1fLZgA1EuFZfolA-cZmXSG9JtJmcBjhdU/view?usp=sharing
[c4-w3-v5]: https://drive.google.com/file/d/1fFQfOBZ_zG1EJs87VkeFfyXOJp8lm_HB/view?usp=sharing
[c4-w3-r51]: https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence
[c4-w3-r52]: https://arxiv.org/abs/2002.07514
[c4-w3-v6]: https://drive.google.com/file/d/1emG-IbioVCWZ7vQ0OsPNZ7Z1bCyYwP5Q/view?usp=sharing
[c4-w3-n6]: https://colab.research.google.com/drive/1KDrCq9pIXbcLkZQen5Ebvy2KdrBeyRfJ
[c4-w3-r6]: https://colab.research.google.com/drive/1swA7AYMqPuOuLzLwkY4UXsEyuYFLFdTf
[c3-w3-hw]: https://colab.research.google.com/drive/1PNW07rSJU6_9c6agkQgrOWZNqkWkbnGi
[c4-w4-v1]: https://drive.google.com/file/d/1dEhtn3SxEC4PZBDHW6xB4127YoLI1Dj6/view?usp=sharing
[c4-w4-r1]: https://drive.google.com/file/d/1czzbx4jmSAA3o6hm2c6J05Tc0EyW13S8/view?usp=sharing
[c4-w4-v2]: https://drive.google.com/file/d/1dbCcNF79LX7I3h2Q8K9m2fpW4nrs34WF/view?usp=sharing
[c4-w4-r2]: https://arxiv.org/abs/1706.02515
[c4-w4-v3]: https://drive.google.com/file/d/1dXcOdu43EiqZPdi6zdQ1HMvKH2MO3fOe/view?usp=sharing
[c4-w4-n3]: https://colab.research.google.com/drive/15r1BIaYLKUcbEHhnvLXaNx_CImSvu_ge
[c4-w4-v4]: https://drive.google.com/file/d/1dSp2iEnd3e_9hZDYCbw__UghqtrUZeo3/view?usp=sharing
[c4-w4-r41]: https://arxiv.org/pdf/1511.06434.pdf
[c4-w4-r42]: https://www.tensorflow.org/api_docs/python/tf/keras/layers/LeakyReLU
[c4-w4-n4]: https://colab.research.google.com/drive/1wUJxiEpvv6BZXa9Sv0AlA2q4lnZSUdiO
[c4-w4-v5]: https://drive.google.com/file/d/1dM9FXjFFxHzvaXdEmLtBFAo_O3MTgsBB/view?usp=sharing
[c4-w4-v6]: https://drive.google.com/file/d/1dv1713N0qgQ38BDCLmXK9vMfIHUu_hS5/view?usp=sharing
[c4-w4-r6]: https://arxiv.org/abs/1607.06450
[c4-w4-n6]: https://colab.research.google.com/drive/1qjg788mqvROFYQmRxQfJ6FtT7uIAfqPz
[c4-w4-hw]: https://colab.research.google.com/drive/1D7jxqH8YqwZTDSGv33yIbGgTMSkg_o30
