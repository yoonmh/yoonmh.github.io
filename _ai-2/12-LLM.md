---
title: "LLM 기초 (24/05/02)"
layout: single
---

> LLM과 RAG 이해

## 1. 자연어 처리
* [강의자료][1-1]
* [OpenAI Key 발급 방법][1-2]
* [자연어 이해][1-3]
* [Instruct GPT][1-4]
* [Prompt-Baed Learning][1-5]
* [Embeddings][1-6]
* [ChatGPT Token][1-7]
* [ChatGPT Pricing][1-8]
* [ChatGPT 기사][1-9]
* [BloombergGPT-1][1-10]
* [BloombergGPT-2][1-11]
* [BloombergGPT-3][1-12]
* [Hugging Face][1-13]
* [Code Alpaca][1-14]
* [RAG][1-15]
* [초록마을][1-16]
* [Sentence Similarity][1-17]
* [Azure][1-18]
* [LangChain][1-19]
* 

## 2. LLM 모델
* [강의자료][2-1]
* [Hugging Face 토큰 발급 방법][2-2]

[1-1]: https://drive.google.com/file/d/1oT7mn3KjRAy7AlGYMln-oLLGk7nHj5wU/view
[1-2]: https://drive.google.com/file/d/1oYLOBR-8HER-eFZEGYMSZUE5xk61cvJI/view
[1-3]: https://woongsin94.tistory.com/341
[1-4]: https://www.theinsaneapp.com/2023/05/everything-about-instructgpt.html
[1-5]: https://developers.reinfer.io/blog/2022/05/04/prompting
[1-6]: https://towardsdatascience.com/embeddings-chatgpts-secret-weapon-1870e590f32c
[1-7]: https://www.makeuseof.com/what-is-chatgpt-token-limit-can-you-exceed-it/
[1-8]: https://openai.com/api/pricing
[1-9]: https://m.mk.co.kr/news/it/10868530
[1-10]: https://www.linkedin.com/pulse/what-i-learned-from-bloombergs-experience-building-own-chanen-phd/
[1-11]: https://www.youtube.com/watch?v=3ZqJaL1jJN4
[1-12]: https://www.bloomberg.com/company/press/bloomberggpt-50-billion-parameter-llm-tuned-finance/
[1-13]: https://huggingface.co/docs/transformers/training
[1-14]: https://github.com/sahil280114/codealpaca
[1-15]: https://m.kmib.co.kr/view_amp.asp?arcid=0924293095
[1-16]: https://news.mt.co.kr/mtview.php?no=2023081010234353171
[1-17]: https://huggingface.co/tasks/sentence-similarity
[1-18]: https://github.com/Azure-Samples/azure-search-openai-demo
[1-19]: https://medium.com/sopmac-ai/chatgpt-langchain-example-for-chatbot-q-a-a8b6ef40bbb6

[2-1]: https://drive.google.com/file/d/1oLTtvJKyHmHp-uZDRJbA-lmAMSQnPhG8/view
[2-2]: https://drive.google.com/file/d/1oadlBRBUlhznPbjdD3WEecuW3xHIIlkm/view
